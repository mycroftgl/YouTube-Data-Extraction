{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmj5FUsawmVh"
      },
      "source": [
        "**YouTube Data Extraction**\n",
        "\n",
        "*   \"###\" - Comment\n",
        "*   \"### abc ###\" - Comment with Actions\n",
        "*   \"#\" - Redacted Code\n",
        "*   \"#\" following code - In Code Comment\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceRK7IiBVZh5"
      },
      "source": [
        "**1. Set Up**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnS08swIviyg"
      },
      "outputs": [],
      "source": [
        "### Import relevant libraries\n",
        "import os\n",
        "import re\n",
        "from datetime import datetime, timedelta\n",
        "import pandas as pd\n",
        "import dask.dataframe as dd\n",
        "from dask.diagnostics import ProgressBar\n",
        "import numpy as np\n",
        "import psutil\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from googleapiclient.errors import HttpError\n",
        "from google.colab import files\n",
        "!pip install youtube-transcript-api\n",
        "from youtube_transcript_api import YouTubeTranscriptApi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wMxrjo69pnXx"
      },
      "outputs": [],
      "source": [
        "### API KEYS - Portion some API Keys to be used for Channel and Video datasets\n",
        "###            and some API Keys to be used in the list for Comment dataset.\n",
        "### This is an area to store API Keys for Access during development.\n",
        "### Please use a secure location to store API Keys when this file is not active.\n",
        "### 1.\n",
        "### 2.\n",
        "### 3.\n",
        "### 4.\n",
        "### 5.\n",
        "### 6.\n",
        "### 7.\n",
        "### 8.\n",
        "### 9.\n",
        "### 10.\n",
        "### 11.\n",
        "### 12."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SApFKuxhKNPi"
      },
      "outputs": [],
      "source": [
        "# Check your RAM capacity\n",
        "ram_gb = psutil.virtual_memory().total / (1024**3)\n",
        "print(f'Total RAM: {ram_gb:.2f} GB')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "86eu21-jEJby"
      },
      "outputs": [],
      "source": [
        "### Initialise YouTube API v3\n",
        "### Insert API Key below ###\n",
        "api_key = ''\n",
        "\n",
        "### Install the google-api-python-client package\n",
        "!pip install google-api-python-client\n",
        "\n",
        "### Verify the installation by importing the package\n",
        "from googleapiclient.discovery import build\n",
        "\n",
        "### If you don't see any errors, the installation was successful\n",
        "print(\"google-api-python-client installed and imported successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CuZskDsvFzI3"
      },
      "outputs": [],
      "source": [
        "### Import API Key\n",
        "from googleapiclient.discovery import build\n",
        "\n",
        "### Build \"youtube\" function to use Youtube api, using api_key\n",
        "youtube = build('youtube','v3',developerKey=api_key)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCritwlbViER"
      },
      "source": [
        "**2. Getting Videos for Channels**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vuni32uTKePc"
      },
      "outputs": [],
      "source": [
        "### Getting the list of channel ID's\n",
        "\n",
        "### List of Channel URL's ###\n",
        "channel_urls = ['']\n",
        "channel_ids = []\n",
        "\n",
        "### Get the channel ID using the custom URL\n",
        "for custom_url in channel_urls:\n",
        "    request = youtube.search().list(part='snippet', q=custom_url, type='channel')\n",
        "    response = request.execute()\n",
        "\n",
        "    ### Check if the channel was found\n",
        "    if response['pageInfo']['totalResults'] > 0:\n",
        "        channel_id = response['items'][0]['snippet']['channelId']\n",
        "        channel_ids.append(channel_id)\n",
        "\n",
        "        ### Get detailed statistics using the channel ID\n",
        "        request = youtube.channels().list(part='contentDetails,statistics', id=channel_id)\n",
        "        response = request.execute()\n",
        "\n",
        "        print(f\"Channel: {custom_url}\")\n",
        "        print(response)\n",
        "        print()\n",
        "    else:\n",
        "        print(f\"Channel not found: {custom_url}\")\n",
        "\n",
        "\n",
        "### Output the list of channel IDs\n",
        "print(\"Channel IDs:\", channel_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ow4Dbd7oF7y6"
      },
      "outputs": [],
      "source": [
        "### Getting list of videos on a channel\n",
        "\n",
        "### Loop for \"Channel IDs\"\n",
        "\n",
        "### Initialise\n",
        "### Insert Start and End Dates as desired ###\n",
        "start_date = '2020-01-01'\n",
        "end_date = '2020-12-31'\n",
        "\n",
        "def get_videos_in_date_range(youtube, channel_id, start_date, end_date):\n",
        "    video_ids = []\n",
        "    start_date = datetime.strptime(start_date, '%Y-%m-%d').isoformat() + 'Z'\n",
        "    end_date = datetime.strptime(end_date, '%Y-%m-%d').isoformat() + 'Z'\n",
        "\n",
        "    next_page_token = None\n",
        "    while True:\n",
        "        request = youtube.search().list(\n",
        "            part='id',\n",
        "            channelId=channel_id,\n",
        "            publishedAfter=start_date,\n",
        "            publishedBefore=end_date,\n",
        "            maxResults=50,\n",
        "            pageToken=next_page_token,\n",
        "            type='video'\n",
        "        )\n",
        "        response = request.execute()\n",
        "\n",
        "        for item in response['items']:\n",
        "            video_id = item['id']['videoId']\n",
        "            video_ids.append(video_id)\n",
        "\n",
        "        next_page_token = response.get('nextPageToken')\n",
        "        if next_page_token is None:\n",
        "            break\n",
        "\n",
        "    return video_ids\n",
        "\n",
        "### Get videos in the date range\n",
        "# video_ids = get_videos_in_date_range(youtube, channel_id, start_date, end_date)\n",
        "\n",
        "### Output the video IDs\n",
        "# video_ids\n",
        "\n",
        "### Loop through each Channel ID and get videos in the date range\n",
        "all_video_ids = {}\n",
        "for channel_id in channel_ids:\n",
        "    video_ids = get_videos_in_date_range(youtube, channel_id, start_date, end_date)\n",
        "    all_video_ids[channel_id] = video_ids\n",
        "\n",
        "### Output the video IDs for each channel\n",
        "for channel_id, video_ids in all_video_ids.items():\n",
        "    print(f\"Channel ID: {channel_id} - Video IDs: {video_ids}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3iWr1LsoFZhU"
      },
      "outputs": [],
      "source": [
        "### Checking number of videos in date range for each channel\n",
        "\n",
        "### all_video_ids is the dictionary containing first part (channel_id), and within each channel_id is video_ids\n",
        "\n",
        "for channel_id, video_ids in all_video_ids.items():\n",
        "    print(f\"Channel ID: {channel_id} - Number of Video IDs: {len(video_ids)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "IcN5bB3lKURl"
      },
      "outputs": [],
      "source": [
        "### Count the number of videos\n",
        "# video_count = len(video_ids)\n",
        "# print(f\"Total number of videos: {video_count}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-m-L_keTeAfG"
      },
      "outputs": [],
      "source": [
        "### Function to get video details\n",
        "def get_video_details(video_id):\n",
        "    request = youtube.videos().list(\n",
        "        part='snippet,statistics',\n",
        "        id=video_id\n",
        "    )\n",
        "    response = request.execute()\n",
        "    return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dT6H0-RU6F4Y"
      },
      "outputs": [],
      "source": [
        "### Function to get video transcript\n",
        "def get_video_transcript(video_id):\n",
        "    try:\n",
        "        transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
        "        return \" \".join([entry['text'] for entry in transcript])\n",
        "    except Exception as e:\n",
        "        return f\"Error retrieving transcript: {str(e)}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBC877T94Jwy"
      },
      "source": [
        "**3. Getting Video Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w0hnNZE731Un"
      },
      "outputs": [],
      "source": [
        "### Initialise YouTube API v3\n",
        "### Insert API Key ###\n",
        "api_key = ''\n",
        "\n",
        "### Install the google-api-python-client package\n",
        "!pip install google-api-python-client\n",
        "\n",
        "### Verify the installation by importing the package\n",
        "from googleapiclient.discovery import build\n",
        "\n",
        "### If you don't see any errors, the installation was successful\n",
        "print(\"google-api-python-client installed and imported successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qBZYVQhe36f_"
      },
      "outputs": [],
      "source": [
        "### Build \"youtube\" function to use Youtube api, using api_key\n",
        "youtube = build('youtube','v3',developerKey=api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Y_xjOKhMtnVh"
      },
      "outputs": [],
      "source": [
        "### List to store video details\n",
        "video_data = []\n",
        "\n",
        "### Loop through all channels and their video IDs to get details\n",
        "for channel, video_ids in tqdm(all_video_ids.items(), desc=\"Channels\"):\n",
        "    for video_id in tqdm(video_ids, desc=f\"Videos in {channel}\", leave=False):\n",
        "        try:\n",
        "            video_details = get_video_details(video_id)\n",
        "            snippet = video_details['items'][0]['snippet']\n",
        "            statistics = video_details['items'][0]['statistics']\n",
        "            content_details = video_details['items'][0]['contentDetails']\n",
        "            transcript = get_video_transcript(video_id)\n",
        "            video_data.append({\n",
        "                'channel_id': snippet['channelId'],\n",
        "                'video_id': video_id,\n",
        "                'title': snippet['title'],  # Added title\n",
        "                'description': snippet['description'],\n",
        "                'published_at': snippet['publishedAt'],\n",
        "                'duration': content_details['duration'],  # Added duration\n",
        "                'likes': statistics.get('likeCount', 'N/A'),\n",
        "                'dislikes': statistics.get('dislikeCount', 'N/A'),\n",
        "                'views': statistics.get('viewCount', 'N/A'),\n",
        "                'comment_count': statistics.get('commentCount', 'N/A'),  # Added comment count\n",
        "                'transcript': transcript\n",
        "            })\n",
        "        except Exception as e:\n",
        "            video_data.append({\n",
        "                'channel_id': 'N/A',\n",
        "                'video_id': video_id,\n",
        "                'title': 'N/A',  # Added title in error case\n",
        "                'description': f\"Error retrieving description: {str(e)}\",\n",
        "                'published_at': 'N/A',\n",
        "                'duration': 'N/A',  # Added duration in error case\n",
        "                'likes': 'N/A',\n",
        "                'dislikes': 'N/A',\n",
        "                'views': 'N/A',\n",
        "                'comment_count': 'N/A',  # Added comment count in error case\n",
        "                'transcript': f\"Error retrieving transcript: {str(e)}\"\n",
        "            })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5UDKKBu1FHF"
      },
      "outputs": [],
      "source": [
        "### Create a DataFrame\n",
        "df = pd.DataFrame(video_data, columns=['channel_id', 'video_id', 'description', 'likes', 'dislikes', 'transcript'])\n",
        "\n",
        "### Convert the pandas DataFrame to a Dask DataFrame\n",
        "ddf = dd.from_pandas(df, npartitions=1)\n",
        "\n",
        "### Display the top 5 rows of the Dask DataFrame\n",
        "print(ddf.head(5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tfAMU-8cbuVt"
      },
      "outputs": [],
      "source": [
        "### Check Final Rows\n",
        "print(ddf.tail(5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_iSB5Dt06Ife"
      },
      "outputs": [],
      "source": [
        "### Define the CSV file path\n",
        "csv_path = '/mnt/data/video_details.csv'\n",
        "\n",
        "### Remove the file if it already exists\n",
        "if os.path.exists(csv_path):\n",
        "    os.remove(csv_path)\n",
        "\n",
        "### Save the Dask DataFrame to a CSV file\n",
        "ddf.to_csv(csv_path, single_file=True)\n",
        "\n",
        "### Download the CSV file\n",
        "files.download(csv_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gGIYZs7Vs2K"
      },
      "source": [
        "**3. Scraping Comments for Videos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GsDo16-PZG_9"
      },
      "outputs": [],
      "source": [
        "### List of API keys from different projects\n",
        "### Insert Remaining API Keys for Comment Dataset\n",
        "api_keys = ['']\n",
        "current_api_key_index = 0\n",
        "\n",
        "### Function to initialize the YouTube API client\n",
        "def initialize_youtube(api_key):\n",
        "    return build('youtube', 'v3', developerKey=api_key)\n",
        "\n",
        "youtube = initialize_youtube(api_keys[current_api_key_index])\n",
        "\n",
        "def rotate_api_key():\n",
        "    global current_api_key_index, youtube\n",
        "    current_api_key_index = (current_api_key_index + 1) % len(api_keys)\n",
        "    youtube = initialize_youtube(api_keys[current_api_key_index])\n",
        "\n",
        "def getcomments(video):\n",
        "    comments = []\n",
        "    while True:\n",
        "        try:\n",
        "            request = youtube.commentThreads().list(\n",
        "                part=\"snippet\",\n",
        "                videoId=video,\n",
        "                maxResults=100\n",
        "            )\n",
        "\n",
        "            response = request.execute()\n",
        "\n",
        "            while request is not None:\n",
        "                for item in response['items']:\n",
        "                    comment = item['snippet']['topLevelComment']['snippet']\n",
        "                    public = item['snippet']['isPublic']\n",
        "                    comments.append([\n",
        "                        comment['authorDisplayName'],\n",
        "                        comment['publishedAt'],\n",
        "                        comment['likeCount'],\n",
        "                        comment['textOriginal'],\n",
        "                        comment['videoId'],\n",
        "                        public\n",
        "                    ])\n",
        "\n",
        "                if 'nextPageToken' in response:\n",
        "                    request = youtube.commentThreads().list(\n",
        "                        part=\"snippet\",\n",
        "                        videoId=video,\n",
        "                        maxResults=100,\n",
        "                        pageToken=response['nextPageToken']\n",
        "                    )\n",
        "                    response = request.execute()\n",
        "                else:\n",
        "                    request = None\n",
        "            break\n",
        "\n",
        "        except HttpError as e:\n",
        "            if e.resp.status == 404:\n",
        "                print(f\"Video not found: {video}, skipping...\")\n",
        "                break\n",
        "            elif e.resp.status == 400:\n",
        "                print(f\"Invalid request for video: {video}, skipping...\")\n",
        "                break\n",
        "            elif e.resp.status == 403:\n",
        "                error_reason = str(e)\n",
        "                if 'commentsDisabled' in error_reason:\n",
        "                    print(f\"Comments are disabled for video: {video}\")\n",
        "                    break\n",
        "                elif 'quotaExceeded' in error_reason:\n",
        "                    print(\"Quota exceeded, rotating API key and waiting...\")\n",
        "                    rotate_api_key()\n",
        "                    time.sleep(60)  # Wait for a minute before retrying\n",
        "                else:\n",
        "                    raise\n",
        "            else:\n",
        "                raise\n",
        "\n",
        "    return comments\n",
        "\n",
        "\n",
        "\n",
        "### Initialize an empty Dask DataFrame\n",
        "meta = pd.DataFrame(columns=['author', 'updated_at', 'like_count', 'text', 'video_id', 'public'])\n",
        "ddf = dd.from_pandas(meta, npartitions=1)\n",
        "\n",
        "### Collect comments and construct the DataFrame in chunks\n",
        "for channel_id, video_ids in tqdm(all_video_ids.items(), desc='Channels'):\n",
        "    for video_id in tqdm(video_ids, desc=f'Videos in Channel {channel_id}', leave=False):\n",
        "        comments = getcomments(video_id)\n",
        "        if comments:  # Only proceed if comments were successfully fetched\n",
        "            df_chunk = pd.DataFrame(comments, columns=['author', 'updated_at', 'like_count', 'text', 'video_id', 'public'])\n",
        "            ddf_chunk = dd.from_pandas(df_chunk, npartitions=1)\n",
        "            ddf = dd.concat([ddf, ddf_chunk])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lDFqn5meuyby"
      },
      "outputs": [],
      "source": [
        "ddf.tail(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "N1uNy-cUbxlg"
      },
      "outputs": [],
      "source": [
        "### Compute the final DataFrame with progress bar\n",
        "with ProgressBar():\n",
        "    final_df = ddf.compute()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AqoYGX6ucUsr"
      },
      "outputs": [],
      "source": [
        "final_df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xCvnspVhcRa7"
      },
      "outputs": [],
      "source": [
        "# Replace problematic characters if needed\n",
        "final_df['text'] = final_df['text'].str.replace('\\n', ' ')\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "final_df.to_csv('all_comments.csv', index=False, escapechar='\\\\')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "npltGCG1tRVN",
        "outputId": "1b034905-96de-4715-e6d3-256d47db9143"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_3b063310-3767-4cb6-ad60-74aedcf96b12\", \"all_comments.csv\", 37911537)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Save the DataFrame to a CSV file\n",
        "csv_filename = 'all_comments.csv'\n",
        "final_df.to_csv(csv_filename, index=False, escapechar='\\\\')\n",
        "\n",
        "# Download the CSV file\n",
        "files.download(csv_filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Optional Merge**"
      ],
      "metadata": {
        "id": "DduRLf-Y_Cci"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bKWjnqgWMTzC"
      },
      "outputs": [],
      "source": [
        "### Merge Video Dataset and Comment Dataset\n",
        "full_data = dd.merge(ddf, final_df, on='video_id', how='inner')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}